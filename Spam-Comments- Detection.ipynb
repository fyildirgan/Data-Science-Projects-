{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                COMMENT_ID                   AUTHOR  \\\n",
      "137    z122f10gdvathpo2222pshcxxpjliddjv04             BmwManDexter   \n",
      "94   z132v5iajkjuhfkyn04cg3mxclnnzj0yxmo0k               richardex8   \n",
      "4      z13fwbwp1oujthgqj04chlngpvzmtt3r3dw                   GsMega   \n",
      "169      z13dtz1zzkagdromt230g5cqfsejstr3p  Digital Media Butterfly   \n",
      "27     z13kszcinpnvc34v2234fnpxkpmlw3nhc04               Kyle Jaber   \n",
      "\n",
      "                    DATE                                            CONTENT  \\\n",
      "137  2014-11-05T20:33:15  check out \"starlitnightsky\" channel to see epi...   \n",
      "94   2014-11-03T23:03:03  Why does this video have so many views? Becaus...   \n",
      "4    2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
      "169  2014-11-06T18:55:14  The most watched video on YouTube is Psy’s “Ga...   \n",
      "27   2014-01-19T00:21:29            Check me out! I'm kyle. I rap so yeah ﻿   \n",
      "\n",
      "     CLASS  \n",
      "137      1  \n",
      "94       0  \n",
      "4        1  \n",
      "169      0  \n",
      "27       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "data = pd.read_csv('Youtube01-Psy.csv')\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               CONTENT  CLASS\n",
      "301  http://hackfbaccountlive.com/?ref=4436607  psy...      1\n",
      "57   Subscribe and like to me for more how to video...      1\n",
      "322            I think he was drunk during this :) x)﻿      0\n",
      "134                              ❤️ ❤️ ❤️ ❤️ ❤️❤️❤️❤️﻿      0\n",
      "27             Check me out! I'm kyle. I rap so yeah ﻿      1\n"
     ]
    }
   ],
   "source": [
    "#We only need the content and class column from the dataset for the rest of the task. So let’s select both the columns and move further:\n",
    "data = data[['CONTENT', 'CLASS']]\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               CONTENT         CLASS\n",
      "86                  Suscribe My Channel Please XD lol﻿  Spam Comment\n",
      "225  You think you're smart?        Headbutt your f...          Spam\n",
      "271  For all of the little kidz out there there is ...          Spam\n",
      "25   marketglory . com/strategygame/andrijamatf ear...  Spam Comment\n",
      "142  pls http://www10.vakinha.com.br/VaquinhaE.aspx...  Spam Comment\n"
     ]
    }
   ],
   "source": [
    "#The class column contains values 0 and 1. 0 indicates not spam, and 1 indicates spam. So to make it look better, I will use spam and not spam labels instead of 1 and 0:\n",
    "data['CLASS'] = data['CLASS'].map({0: 'Spam',\n",
    "                                    1: 'Spam Comment'})\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "#Now let’s move further by training a classification Machine Learning model to classify spam and not spam comments. As this problem is a problem of binary classification, I will use the Bernoulli Naive Bayes algorithm to train the model:\n",
    "x = np.array(data['CONTENT'])\n",
    "y = np.array(data['CLASS'])\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spam Comment']\n"
     ]
    }
   ],
   "source": [
    "#Now let’s test the model by giving spam and not spam comments as input:\n",
    "sample = 'Check this out: https://thecleverprogrammer.com/'\n",
    "data = cv.transform([sample]).toarray()\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spam']\n"
     ]
    }
   ],
   "source": [
    "sample = 'Lack of information!'\n",
    "data = cv.transform([sample]).toarray()\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary\n",
    "#Spam comments detection means classifying comments as spam or not spam. Spam comments on social media platforms are the type of comments posted to redirect the user to another social media account, website or any piece of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4710a83545741eb845e39d42f17946b18e65be580c75e0ca94b4f9fab7f0d016"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
