{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the above section, I started the task of stock price prediction by importing the python libraries. Now I will write a function that will prepare the dataset so that we can fit it easily in the Linear Regression model:\n",
    "def prepare_data(df, forecast_col, forecast_out, test_size):\n",
    "    label = df[forecast_col].shift(-forecast_col) #creating new column called label with the last 5 rows are nan\n",
    "    X =np.array(df[[forecast_col]]) #creating the feature array\n",
    "    X = preprocessing.scale(X) #processing the feature array\n",
    "    X_lately = X[-forecast_out:] #creating the column i want to use later in the predicting method\n",
    "    X = X[:-forecast_out] # X that will contain the training and testing\n",
    "    label.dropna(inplace=True) #dropping na values\n",
    "    y = np.array(label) # assigning Y\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_size, random_state=0) #cross validation\n",
    "    response = [X_train, X_test, Y_train, Y_test, X_lately]\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the next thing to do is reading the data:\n",
    "df = pd.read_csv(\"prices.csv\")\n",
    "df = df[df.symbol == \"GOOG\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to prepare three input variables as already prepared in the function created in the above section. We need to declare an input variable mentioning about which column we want to predict. The next variable we need to declare is how much far we want to predict.\n",
    "#And the last variable that we need to declare is how much should be the size of the test set. Now let’s declare all the variables:\n",
    "forecast_col = 'close'\n",
    "forecast_out = 5\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will split the data and fit into the linear regression model:\n",
    "X_train, X_test, Y_train, Y_test , X_lately =prepare_data(df,forecast_col,forecast_out,test_size); #calling the method were the cross validation and data preperation is in\n",
    "learner = LinearRegression() #initializing linear regression model\n",
    "\n",
    "learner.fit(X_train,Y_train) #training the linear regression model\n",
    "\n",
    "#output that should be\n",
    "#{‘test_score’: 0.9481024935723803, ‘forecast_set’: array([786.54352516, 788.13020371, 781.84159626, 779.65508615, 769.04187979])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i can't find the data file. so i can't solve the steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4710a83545741eb845e39d42f17946b18e65be580c75e0ca94b4f9fab7f0d016"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
